# 1. 샘플 벡터DB 생성기

# langchain 패키지에서 필요한 모듈들을 불러옵니다.
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# 블로그 글을 로드합니다.
loader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")
data = loader.load()

# 텍스트를 분할합니다.
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
splits = text_splitter.split_documents(data)

# 벡터DB 생성
embedding = OpenAIEmbeddings()
vectordb = Chroma.from_documents(documents=splits, embedding=embedding)


# 2. 검색기

# langchain 패키지에서 MultiQueryRetriever 모듈을 불러옵니다.
from langchain.retrievers.multi_query import MultiQueryRetriever

# langchain_openai 패키지에서 ChatOpenAI 모듈을 불러옵니다.
from langchain_openai import ChatOpenAI

# 질문을 설정합니다.(Task Decomposition에는 어떤 접근 방법들이 있나요?)
question = "What are the approaches to Task Decomposition?"

# ChatOpenAI 객체를 생성하여 언어 생성 모델을 설정합니다.
llm = ChatOpenAI(temperature=0)

# MultiQueryRetriever를 사용하여 언어 생성 모델로부터 검색 모델을 생성합니다.
retriever_from_llm = MultiQueryRetriever.from_llm(
    retriever=vectordb.as_retriever(), llm=llm
)

# 쿼리에 대한 로깅 설정
import logging

logging.basicConfig()
logging.getLogger("langchain.retrievers.multi_query").setLevel(logging.INFO)

# 관련 문서들을 검색하여 unique_docs에 저장합니다.
unique_docs = retriever_from_llm.get_relevant_documents(query=question)

# 검색된 관련 문서들의 개수를 출력합니다.
len(unique_docs)
